{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KycXk3AWB0BT",
        "outputId": "a0a0c2e5-395d-487f-b7f2-0c14d8820a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ===== Versions pinned to match your notebook (embed) =====\n",
        "%pip install -q --upgrade pip\n",
        "%pip uninstall -y -q numpy pandas\n",
        "%pip install -q \\\n",
        "  \"numpy==1.26.4\" \\\n",
        "  \"pandas==2.2.2\" \\\n",
        "  \"transformers==4.40.2\" \\\n",
        "  \"sentence-transformers==2.7.0\" \\\n",
        "  \"accelerate==0.30.1\" \\\n",
        "  \"chromadb==1.0.20\" \\\n",
        "  bitsandbytes \\\n",
        "  tqdm\n",
        "\n",
        "# Web server bits\n",
        "%pip install -q fastapi uvicorn nest_asyncio pyngrok\n",
        "\n",
        "# ---- Hard restart so pinned wheels are actually used (Colab-specific) ----\n",
        "import os\n",
        "print(\"üîÅ Restarting runtime to load pinned wheels ...\")\n",
        "os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY0jwqgW_-ZH",
        "outputId": "450345bf-67f4-4e47-af83-66ddb3989e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token from userdata: f0ab64e29211a096d901e171568e6a3d\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    AUTH_TOKEN = userdata.get('EMBED_SERVER_TOKEN')\n",
        "    print(\"Token from userdata:\", AUTH_TOKEN)\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"Secret not found. Did you add EMBED_SERVER_TOKEN in the sidebar?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "7dbf6128c0aa4e959b4cc1371a5a3148",
            "1910816bae714a6e9e5020741731ced7",
            "d79f2d2348e44720b3379947f22695f8",
            "666e09059e7f4396bb83bf105792b6f5",
            "03041d4099254ab1b6b4c17605aa0c60",
            "f18bda9dae7c44dab61d217f83b2650c",
            "db46a5628176492ebfc88c8405581e6a",
            "ed92d1d265f2482c850c47f3a45b0eea",
            "20a2726c3e694ed68d782a6a55f7a386",
            "6083a6fbd2c1439ca97089a9cab31462",
            "7c60abaf7d634ec8a87a32577c909342"
          ]
        },
        "id": "NwlhZ07X93-D",
        "outputId": "1da9fad6-4a7c-4ce5-bbf3-1b3df56a361d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dbf6128c0aa4e959b4cc1371a5a3148"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Embed model ready on: cuda\n",
            "‚úÖ Using Chroma collection: minecraft_mods_custom_v1 @ /content/drive/MyDrive/chroma_db_custom_model\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Colab Retrieval/Embedding Server (uses DB_DIR)\n",
        "# =========================\n",
        "%pip install -q fastapi uvicorn nest_asyncio\n",
        "\n",
        "import os, torch\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "from huggingface_hub import snapshot_download\n",
        "from transformers import BitsAndBytesConfig  # 8-bit quant\n",
        "from google.colab import drive\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# ---- Config ----\n",
        "HF_REPO_ID = \"Nimiii/nv-embedcode-7b-mine-modder-st\"\n",
        "CACHE_DIR  = \"/content/drive/MyDrive/models/nv-embedcode-7b-mine-modder-st\"\n",
        "DB_DIR     = \"/content/drive/MyDrive/chroma_db_custom_model\"  # <- points to your persisted store\n",
        "COLLECTION = os.environ.get(\"CHROMA_COLLECTION\", \"minecraft_mods_custom_v1\")\n",
        "MAX_LEN    = 2048\n",
        "\n",
        "# Reuse the token you loaded in Cell 2\n",
        "if not AUTH_TOKEN:\n",
        "    raise RuntimeError(\"EMBED_SERVER_TOKEN not found (Colab Secrets).\")\n",
        "\n",
        "# ---- Mount Drive & cache model ----\n",
        "if not os.path.isdir(\"/content/drive\"):\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "if not os.path.isdir(CACHE_DIR):\n",
        "    snapshot_download(repo_id=HF_REPO_ID, local_dir=CACHE_DIR, local_dir_use_symlinks=False)\n",
        "\n",
        "# ---- Load ST model (8-bit backbone, pooled + normalized) ----\n",
        "device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "bnb_cfg = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "word_embedding_model = models.Transformer(\n",
        "    CACHE_DIR,\n",
        "    model_args={\n",
        "        \"trust_remote_code\": True,\n",
        "        \"device_map\": \"auto\",\n",
        "        \"quantization_config\": bnb_cfg,\n",
        "    },\n",
        ")\n",
        "pooling_model   = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "normalize_model = models.Normalize()\n",
        "\n",
        "st_model = SentenceTransformer(\n",
        "    modules=[word_embedding_model, pooling_model, normalize_model],\n",
        "    device=device,\n",
        ")\n",
        "st_model.max_seq_length = MAX_LEN\n",
        "print(f\"‚úÖ Embed model ready on: {device}\")\n",
        "\n",
        "# ---- Chroma client (points to Drive; pinned to 0.4.24 in Cell 1) ----\n",
        "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"FALSE\"\n",
        "client = chromadb.PersistentClient(\n",
        "    path=DB_DIR,\n",
        "    settings=Settings(anonymized_telemetry=False),\n",
        ")\n",
        "\n",
        "# Require an existing collection (avoid silently creating an empty one)\n",
        "names = [c.name for c in client.list_collections()]\n",
        "if COLLECTION not in names:\n",
        "    raise RuntimeError(\n",
        "        f\"Chroma collection '{COLLECTION}' not found in DB_DIR={DB_DIR}. \"\n",
        "        f\"Available: {names}. Re-ingest or set CHROMA_COLLECTION env var.\"\n",
        "    )\n",
        "collection = client.get_collection(COLLECTION)\n",
        "print(f\"‚úÖ Using Chroma collection: {COLLECTION} @ {DB_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGU0UB0mQdy7",
        "outputId": "d10f61f1-c223-4090-c730-1e195d7a19af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [2849]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåç Public URL (ngrok): https://4bb0e08afa86.ngrok-free.app\n",
            "üîê Send header: Authorization: Bearer <EMBED_SERVER_TOKEN>\n",
            "INFO:     85.250.132.139:0 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "# ---- API schema & app ----\n",
        "import time, nest_asyncio, uvicorn\n",
        "from typing import List, Optional, Literal\n",
        "from fastapi import FastAPI, Header, HTTPException\n",
        "from pydantic import BaseModel, Field\n",
        "from google.colab import userdata\n",
        "from pyngrok import ngrok, conf\n",
        "import torch\n",
        "\n",
        "# Assume st_model and collection are initialized elsewhere in your full script\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# import chromadb\n",
        "# st_model = SentenceTransformer(...)\n",
        "# client = chromadb.Client(...)\n",
        "# collection = client.get_collection(...)\n",
        "# AUTH_TOKEN = \"your_auth_token\"\n",
        "\n",
        "\n",
        "class EmbedRequest(BaseModel):\n",
        "    texts: list[str]\n",
        "    normalize: bool = True\n",
        "    precision: str = \"float32\"  # accepted but ignored by SentenceTransformer\n",
        "\n",
        "class Health(BaseModel):\n",
        "    ok: bool\n",
        "    collection: str\n",
        "    count: int\n",
        "    device: str\n",
        "    dim: int\n",
        "    chroma_version: str\n",
        "\n",
        "class RetrieveRequest(BaseModel):\n",
        "    query: str = Field(..., description=\"Natural language query\")\n",
        "    top_k: int = Field(8, ge=1, le=100)\n",
        "    include: List[Literal[\"documents\",\"metadatas\",\"distances\",\"uris\",\"data\"]] = Field(\n",
        "        default_factory=lambda: [\"documents\",\"metadatas\",\"distances\"]\n",
        "    )\n",
        "    normalize: bool = True\n",
        "    filters: Optional[dict] = None          # maps to Chroma `where`\n",
        "    where_document: Optional[dict] = None   # maps to Chroma `where_document`\n",
        "    expand_pages_from_top_k: bool = False   # expand by source_file\n",
        "    similarity_threshold: Optional[float] = None  # applies only to the top_k band\n",
        "\n",
        "class Hit(BaseModel):\n",
        "    id: str\n",
        "    distance: Optional[float] = None\n",
        "    similarity: Optional[float] = None\n",
        "    document: Optional[str] = None\n",
        "    metadata: Optional[dict] = None\n",
        "\n",
        "class RetrieveResponse(BaseModel):\n",
        "    hits: List[Hit]\n",
        "    applied_top_k: int\n",
        "    include: List[str]\n",
        "    stats: dict\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "def _check_auth(h: Optional[str]):\n",
        "    # In a real app, replace with your actual auth token logic\n",
        "    if not AUTH_TOKEN or h != f\"Bearer {AUTH_TOKEN}\":\n",
        "        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n",
        "\n",
        "# --- helper to convert L2 distance between unit vectors to similarity in [0,1] ---\n",
        "def _l2_to_sim01(d: Optional[float]) -> Optional[float]:\n",
        "    if d is None:\n",
        "        return None\n",
        "    d = float(d)\n",
        "    cos = 1.0 - (d * d) / 2.0           # cosine in [-1, 1]\n",
        "    cos = max(-1.0, min(1.0, cos))\n",
        "    return (cos + 1.0) / 2.0            # similarity in [0, 1]\n",
        "\n",
        "@app.get(\"/health\", response_model=Health)\n",
        "def health(authorization: str = Header(None)):\n",
        "    _check_auth(authorization)\n",
        "    try:\n",
        "        cnt = collection.count()\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Chroma error: {e}\")\n",
        "    try:\n",
        "        dim = st_model.get_sentence_embedding_dimension()\n",
        "    except Exception:\n",
        "        dim = len(st_model.encode([\"x\"], normalize_embeddings=True)[0])\n",
        "    import chromadb as _c\n",
        "    return Health(\n",
        "        ok=True,\n",
        "        collection=COLLECTION,\n",
        "        count=cnt,\n",
        "        device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "        dim=int(dim),\n",
        "        chroma_version=getattr(_c, \"__version__\", \"unknown\"),\n",
        "    )\n",
        "\n",
        "@app.post(\"/embed\")\n",
        "def embed(req: EmbedRequest, authorization: str = Header(None)):\n",
        "    _check_auth(authorization)\n",
        "    with torch.no_grad():\n",
        "        vecs = st_model.encode(\n",
        "            req.texts,\n",
        "            convert_to_tensor=True,\n",
        "            normalize_embeddings=req.normalize,\n",
        "            show_progress_bar=False,\n",
        "        ).float().cpu().tolist()\n",
        "    return {\"vectors\": vecs, \"dim\": (len(vecs[0]) if vecs else 0)}\n",
        "\n",
        "@app.post(\"/retrieve\", response_model=RetrieveResponse)\n",
        "def retrieve(req: RetrieveRequest, authorization: str = Header(None)):\n",
        "    _check_auth(authorization)\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        q_emb = st_model.encode(\n",
        "            [req.query],\n",
        "            convert_to_tensor=True,\n",
        "            normalize_embeddings=req.normalize,\n",
        "            show_progress_bar=False,\n",
        "        ).float().cpu().tolist()\n",
        "    t_embed = (time.perf_counter() - t0) * 1000\n",
        "\n",
        "    t1 = time.perf_counter()\n",
        "    try:\n",
        "        res = collection.query(\n",
        "            query_embeddings=q_emb,\n",
        "            n_results=req.top_k,\n",
        "            include=req.include,\n",
        "            where=req.filters,\n",
        "            where_document=req.where_document\n",
        "        )\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Chroma query failed: {e}\")\n",
        "    t_query = (time.perf_counter() - t1) * 1000\n",
        "\n",
        "    ids       = res.get(\"ids\", [[]])[0]\n",
        "    distances = res.get(\"distances\", [[]])[0] if \"distances\" in res else [None]*len(ids)\n",
        "    documents = res.get(\"documents\", [[]])[0] if \"documents\" in res else [None]*len(ids)\n",
        "    metadatas = res.get(\"metadatas\", [[]])[0] if \"metadatas\" in res else [None]*len(ids)\n",
        "\n",
        "    # 1. Build initial top-k hits and apply similarity threshold\n",
        "    top_hits: List[Hit] = []\n",
        "    for i, _id in enumerate(ids):\n",
        "        dist = float(distances[i]) if distances[i] is not None else None\n",
        "        sim = _l2_to_sim01(dist)\n",
        "\n",
        "        if req.similarity_threshold is None or (sim is not None and sim >= req.similarity_threshold):\n",
        "            top_hits.append(Hit(\n",
        "                id=_id,\n",
        "                distance=dist,\n",
        "                similarity=sim,\n",
        "                document=documents[i] if i < len(documents) else None,\n",
        "                metadata=metadatas[i] if i < len(metadatas) else None,\n",
        "            ))\n",
        "\n",
        "    # 2. If expansion is requested, get all pages from the same source_file\n",
        "    all_hits = list(top_hits)\n",
        "    if req.expand_pages_from_top_k and top_hits:\n",
        "        source_files = list(dict.fromkeys(\n",
        "            hit.metadata.get(\"source_file\") for hit in top_hits if hit.metadata and hit.metadata.get(\"source_file\")\n",
        "        ))\n",
        "\n",
        "        if source_files:\n",
        "            expansion_where = {\"source_file\": {\"$in\": source_files}}\n",
        "            if req.filters:\n",
        "                expansion_where = {\"$and\": [req.filters, expansion_where]}\n",
        "\n",
        "            try:\n",
        "                page_res = collection.get(\n",
        "                    where=expansion_where,\n",
        "                    include=[\"documents\", \"metadatas\"]\n",
        "                )\n",
        "\n",
        "                page_ids = page_res.get(\"ids\", [])\n",
        "                page_docs = page_res.get(\"documents\", [])\n",
        "                page_metas = page_res.get(\"metadatas\", [])\n",
        "\n",
        "                # 3. Add expanded docs, avoiding duplicates\n",
        "                existing_ids = {h.id for h in all_hits}\n",
        "                for i, page_id in enumerate(page_ids):\n",
        "                    if page_id not in existing_ids:\n",
        "                        meta = page_metas[i] if i < len(page_metas) else {}\n",
        "                        if meta:\n",
        "                            meta[\"_expanded_from_source_file\"] = meta.get(\"source_file\")\n",
        "\n",
        "                        all_hits.append(Hit(\n",
        "                            id=page_id,\n",
        "                            distance=None,\n",
        "                            similarity=None, # Expanded pages have no similarity score\n",
        "                            document=page_docs[i] if i < len(page_docs) else None,\n",
        "                            metadata=meta,\n",
        "                        ))\n",
        "            except Exception as e:\n",
        "                # Fail gracefully: log the error but return the top hits found so far\n",
        "                print(f\"Warning: Page expansion query failed: {e}\")\n",
        "\n",
        "\n",
        "    return RetrieveResponse(\n",
        "        hits=all_hits,\n",
        "        applied_top_k=len(top_hits), # This count is pre-expansion\n",
        "        include=req.include,\n",
        "        stats={\n",
        "            \"embed_ms\": round(t_embed, 2),\n",
        "            \"query_ms\": round(t_query, 2),\n",
        "            \"total_ms\": round((time.perf_counter() - t0) * 1000, 2),\n",
        "            \"normalized\": req.normalize,\n",
        "            \"top_k_before_expansion\": len(top_hits),\n",
        "            \"total_hits_after_expansion\": len(all_hits),\n",
        "        },\n",
        "    )\n",
        "\n",
        "# ---- Expose via ngrok (if running in Colab) ----\n",
        "nest_asyncio.apply()\n",
        "NGROK_TOKEN = userdata.get(\"NGROK_TOKEN\")\n",
        "if not NGROK_TOKEN:\n",
        "    raise RuntimeError(\"NGROK_TOKEN not found in Colab Secrets.\")\n",
        "conf.get_default().region = \"eu\"\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "print(\"üåç Public URL (ngrok):\", public_url)\n",
        "print(\"üîê Send header: Authorization: Bearer <EMBED_SERVER_TOKEN>\")\n",
        "\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7dbf6128c0aa4e959b4cc1371a5a3148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1910816bae714a6e9e5020741731ced7",
              "IPY_MODEL_d79f2d2348e44720b3379947f22695f8",
              "IPY_MODEL_666e09059e7f4396bb83bf105792b6f5"
            ],
            "layout": "IPY_MODEL_03041d4099254ab1b6b4c17605aa0c60"
          }
        },
        "1910816bae714a6e9e5020741731ced7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f18bda9dae7c44dab61d217f83b2650c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_db46a5628176492ebfc88c8405581e6a",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "d79f2d2348e44720b3379947f22695f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed92d1d265f2482c850c47f3a45b0eea",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20a2726c3e694ed68d782a6a55f7a386",
            "value": 3
          }
        },
        "666e09059e7f4396bb83bf105792b6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6083a6fbd2c1439ca97089a9cab31462",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7c60abaf7d634ec8a87a32577c909342",
            "value": "‚Äá3/3‚Äá[02:21&lt;00:00,‚Äá44.78s/it]"
          }
        },
        "03041d4099254ab1b6b4c17605aa0c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f18bda9dae7c44dab61d217f83b2650c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db46a5628176492ebfc88c8405581e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed92d1d265f2482c850c47f3a45b0eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a2726c3e694ed68d782a6a55f7a386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6083a6fbd2c1439ca97089a9cab31462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c60abaf7d634ec8a87a32577c909342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}